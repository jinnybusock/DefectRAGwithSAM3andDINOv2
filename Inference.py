# ===================================================================
# 2ë‹¨ê³„: ì‹¤ì‹œê°„ ê²€ì‚¬ - ì‹ ê·œ ì´ë¯¸ì§€ â†’ SAM3 Mask â†’ DINOv2 â†’ Top-5 ê²€ìƒ‰
# ===================================================================

import torch
import os
import sys
from PIL import Image
import numpy as np
import torchvision.transforms as T

from connection import initialize_project

initialize_project()

from sam3 import build_sam3_image_model
from DINOv2_FeatureMap import get_multiple_defect_boxes

device = "cuda" if torch.cuda.is_available() else "cpu"

# 1. ëª¨ë¸ ë¡œë“œ
print("=" * 70)
print("ëª¨ë¸ ë¡œë”© ì¤‘...")
print("=" * 70)

# DINOv2 ëª¨ë¸
model_dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14').to(device)
model_dinov2.eval()
print("âœ“ DINOv2 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# SAM3 ëª¨ë¸
sam3_model = build_sam3_image_model(
    checkpoint_path=r"C:\Users\hjchung\Desktop\sam3\checkpoints\sam3.pt"
).to(device)
sam3_model.eval()
print("âœ“ SAM3 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")


# 2. ì „ì²´ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜
def process_new_defect_image(image_path, dinov2_model, sam3_model, device):
    """
    ì‹ ê·œ ê²°í•¨ ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    1) DINOv2ë¡œ ê²°í•¨ ìœ„ì¹˜(box) ì°¾ê¸°
    2) SAM3ë¡œ ì •ë°€í•œ Mask ìƒì„±
    3) Mask ì˜ì—­ì—ì„œ DINOv2 íŠ¹ì§• ì¶”ì¶œ
    4) DBì—ì„œ Top-5 ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰
    """

    print(f"\n{'=' * 70}")
    print(f"ğŸ“¸ ì‹ ê·œ ì´ë¯¸ì§€ ë¶„ì„: {os.path.basename(image_path)}")
    print(f"{'=' * 70}")

    # Step 1: DINOv2ë¡œ ê²°í•¨ ë°•ìŠ¤ ì°¾ê¸° (Tiling)
    print("\n[Step 1] DINOv2ë¡œ ê²°í•¨ ìœ„ì¹˜ ì°¾ê¸°...")
    defect_boxes = get_multiple_defect_boxes(image_path, dinov2_model, device)

    if not defect_boxes:
        print("âœ— ê²°í•¨ì´ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    print(f"âœ“ {len(defect_boxes)}ê°œì˜ ê²°í•¨ ì˜ì—­ íƒì§€!")

    # ì²« ë²ˆì§¸ ë°•ìŠ¤ ì‚¬ìš© (ë˜ëŠ” ê°€ì¥ í° ë°•ìŠ¤ ì„ íƒ ê°€ëŠ¥)
    defect_box = defect_boxes[0]
    print(f"  - ì„ íƒëœ ë°•ìŠ¤ [x, y, w, h]: {[f'{x:.1f}' for x in defect_box]}")

    # Step 2: SAM3ë¡œ ì •ë°€í•œ Mask ìƒì„±
    print("\n[Step 2] SAM3ë¡œ ì •ë°€ Mask ìƒì„±...")

    img = Image.open(image_path).convert("RGB")
    img_width, img_height = img.size

    # SAM3 ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    img_array = np.array(img)

    # Box ì¢Œí‘œë¥¼ SAM3 í˜•ì‹ìœ¼ë¡œ ë³€í™˜ [x1, y1, x2, y2]
    x, y, w, h = defect_box
    box_sam = np.array([x, y, x + w, y + h])

    with torch.no_grad():
        # SAM3ì— ì´ë¯¸ì§€ì™€ ë°•ìŠ¤ ì „ë‹¬
        sam3_model.set_image(img_array)

        masks, scores, _ = sam3_model.predict(
            point_coords=None,
            point_labels=None,
            box=box_sam[None, :],  # [1, 4] í˜•íƒœ
            multimask_output=False
        )

    # ê°€ì¥ ì¢‹ì€ ë§ˆìŠ¤í¬ ì„ íƒ
    best_mask = masks[0]  # [H, W]
    print(f"âœ“ Mask ìƒì„± ì™„ë£Œ! (í¬ê¸°: {best_mask.shape})")

    # Step 3: Mask ì˜ì—­ì—ì„œ DINOv2 íŠ¹ì§• ì¶”ì¶œ
    print("\n[Step 3] Mask ì˜ì—­ì—ì„œ íŠ¹ì§• ì¶”ì¶œ...")

    # Maskë¥¼ ì ìš©í•œ ì´ë¯¸ì§€ ìƒì„±
    masked_img = img_array.copy()
    masked_img[~best_mask] = 0  # Mask ì™¸ë¶€ëŠ” ê²€ì€ìƒ‰

    masked_pil = Image.fromarray(masked_img)

    # DINOv2ë¡œ íŠ¹ì§• ì¶”ì¶œ
    transform = T.Compose([
        T.Resize((224, 224)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    img_tensor = transform(masked_pil).unsqueeze(0).to(device)

    with torch.no_grad():
        features = dinov2_model(img_tensor)
        query_vector = features.cpu().numpy().flatten()

    print(f"âœ“ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ ì™„ë£Œ! (ì°¨ì›: {len(query_vector)})")

    # Step 4: PostgreSQLì—ì„œ Top-5 ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰
    print("\n[Step 4] DBì—ì„œ ìœ ì‚¬ ì´ë¯¸ì§€ Top-5 ê²€ìƒ‰...")

    try:
        import psycopg2

        conn = psycopg2.connect(
            host="localhost",
            database="defect_db",
            user="postgres",
            password="your_password"
        )
        cur = conn.cursor()

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ Top-5 ê²€ìƒ‰
        cur.execute("""
            SELECT 
                id,
                defect_type,
                filename,
                1 - (feature_vector <=> %s::vector) AS similarity
            FROM defect_images
            ORDER BY feature_vector <=> %s::vector
            LIMIT 5;
        """, (query_vector.tolist(), query_vector.tolist()))

        top5_results = cur.fetchall()

        cur.close()
        conn.close()

        print(f"\n{'=' * 70}")
        print("ğŸ† Top-5 ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼")
        print(f"{'=' * 70}")
        print(f"{'ìˆœìœ„':<6} {'Defect íƒ€ì…':<15} {'íŒŒì¼ëª…':<30} {'ìœ ì‚¬ë„':<10}")
        print("-" * 70)

        predicted_defect = None
        for rank, (img_id, defect_type, filename, similarity) in enumerate(top5_results, 1):
            print(f"{rank:<6} {defect_type:<15} {filename:<30} {similarity:.4f}")
            if rank == 1:
                predicted_defect = defect_type

        print(f"{'=' * 70}")
        print(f"\nâœ… ìµœì¢… íŒì •: [{predicted_defect}] íƒ€ì…ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        print(f"{'=' * 70}\n")

        return {
            "image_path": image_path,
            "defect_box": defect_box,
            "mask": best_mask,
            "feature_vector": query_vector,
            "predicted_defect": predicted_defect,
            "top5_results": top5_results
        }

    except ImportError:
        print("âš ï¸ PostgreSQL ì—°ê²° ì‹¤íŒ¨. ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©...")

        import pickle
        with open('defect_database.pkl', 'rb') as f:
            defect_db = pickle.load(f)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        from scipy.spatial.distance import cosine

        similarities = []
        for item in defect_db:
            sim = 1 - cosine(query_vector, item['feature_vector'])
            similarities.append({
                'defect_type': item['defect_type'],
                'filename': item['filename'],
                'similarity': sim
            })

        # Top-5 ì •ë ¬
        top5 = sorted(similarities, key=lambda x: x['similarity'], reverse=True)[:5]

        print(f"\n{'=' * 70}")
        print("ğŸ† Top-5 ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼ (ë¡œì»¬ DB)")
        print(f"{'=' * 70}")
        print(f"{'ìˆœìœ„':<6} {'Defect íƒ€ì…':<15} {'íŒŒì¼ëª…':<30} {'ìœ ì‚¬ë„':<10}")
        print("-" * 70)

        for rank, item in enumerate(top5, 1):
            print(f"{rank:<6} {item['defect_type']:<15} {item['filename']:<30} {item['similarity']:.4f}")

        predicted_defect = top5[0]['defect_type']

        print(f"{'=' * 70}")
        print(f"\nâœ… ìµœì¢… íŒì •: [{predicted_defect}] íƒ€ì…ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        print(f"{'=' * 70}\n")

        return {
            "image_path": image_path,
            "defect_box": defect_box,
            "mask": best_mask,
            "feature_vector": query_vector,
            "predicted_defect": predicted_defect,
            "top5_results": top5
        }

    except Exception as e:
        print(f"âœ— ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return None


# 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸í•  ì‹ ê·œ ì´ë¯¸ì§€ ê²½ë¡œ (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½)
    test_image = r"C:\Users\hjchung\Desktop\test_defect.jpg"

    if os.path.exists(test_image):
        result = process_new_defect_image(test_image, model_dinov2, sam3_model, device)

        if result:
            print("\nâœ“ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")

            # (ì„ íƒ) ê²°ê³¼ ì €ì¥
            # import pickle
            # with open('inference_result.pkl', 'wb') as f:
            #     pickle.dump(result, f)
    else:
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_image}")
        print("test_image ë³€ìˆ˜ë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”.")
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T
from PIL import Image
import os
import random
from connection import initialize_project

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì´ˆê¸°í™”
initialize_project()


class SemiconductorTripletDataset(Dataset):
    def __init__(self, base_path, transform=None):
        self.base_path = base_path
        self.transform = transform
        self.classes = [c for c in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, c))]

        # 'good' í´ë˜ìŠ¤ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ í™•ë³´ (Anchor & Positive ìš©)
        self.good_images = [os.path.join(base_path, 'good', f)
                            for f in os.listdir(os.path.join(base_path, 'good'))
                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

        # ê²°í•¨ í´ë˜ìŠ¤ë“¤ (Negative ìš©)
        self.defect_classes = [c for c in self.classes if c != 'good']

    def __len__(self):
        return len(self.good_images)

    def __getitem__(self, idx):
        # 1. Anchor: í˜„ì¬ 'good' ì´ë¯¸ì§€
        anchor_path = self.good_images[idx]

        # 2. Positive: ë˜ ë‹¤ë¥¸ ëœë¤ 'good' ì´ë¯¸ì§€
        pos_path = random.choice(self.good_images)
        while pos_path == anchor_path:
            pos_path = random.choice(self.good_images)

        # 3. Negative: ê²°í•¨ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ì—ì„œ ëœë¤ ì„ íƒ
        neg_class = random.choice(self.defect_classes)
        neg_folder = os.path.join(self.base_path, neg_class)
        neg_path = os.path.join(neg_folder, random.choice(os.listdir(neg_folder)))

        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        anchor = self.transform(Image.open(anchor_path).convert('RGB'))
        positive = self.transform(Image.open(pos_path).convert('RGB'))
        negative = self.transform(Image.open(neg_path).convert('RGB'))

        return anchor, positive, negative


def train():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    base_train_path = r"C:\Users\hjchung\Desktop\RAG Train"

    # 1. ëª¨ë¸ ë¡œë“œ ë° ì–´ëŒ‘í„° ë¶€ì°©
    print("DINOv2 ViT-L/14 ë¡œë”© ì¤‘...")
    dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14').to(device)

    # ê°€ì¤‘ì¹˜ ê³ ì • ì—¬ë¶€ ê²°ì • (Backboneë„ ì‚´ì§ íŠœë‹í•˜ëŠ” ê²ƒì´ ì„±ëŠ¥ì— ì¢‹ìŒ)
    for param in dinov2.parameters():
        param.requires_grad = True

    # 2. ì „ì²˜ë¦¬ ì„¤ì •
    transform = T.Compose([
        T.Resize((224, 224)),
        T.RandomHorizontalFlip(),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # 3. ë°ì´í„° ë¡œë”
    dataset = SemiconductorTripletDataset(base_train_path, transform=transform)
    loader = DataLoader(dataset, batch_size=4, shuffle=True)

    # 4. ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” (TripletMarginLoss ì‚¬ìš©)
    # $L(a, p, n) = \max(d(a, p) - d(a, n) + \text{margin}, 0)$
    criterion = nn.TripletMarginLoss(margin=1.0, p=2)
    optimizer = optim.AdamW(dinov2.parameters(), lr=1e-5)

    print(f"ğŸš€ ëŒ€ì¡° í•™ìŠµ ì‹œì‘ (ì´ë¯¸ì§€: {len(dataset)}ìŒ)...")

    num_epochs = 10

    accumulation_steps = 4     # 4ë²ˆ ëª¨ì•„ì„œ ì—…ë°ì´íŠ¸
    for epoch in range(num_epochs):
        scaler= torch.amp.GradScaler('cuda')
        model_loss = 0.0
        optimizer.zero_grad()     # ë£¨í”„ ë°–ìœ¼ë¡œ ì´ë™

        for i, (anc, pos, neg) in enumerate(loader):
            anc, pos, neg = anc.to(device), pos.to(device), neg.to(device)

            with torch.amp.autocast('cuda'):     # ìë™ ì •ë°€ë„ ì¡°ì ˆ
                # íŠ¹ì§• ì¶”ì¶œ ë° ì†ì‹¤ ê³„ì‚°
                e_anc= dinov2(anc)
                e_pos = dinov2(pos)
                e_neg = dinov2(neg)

                loss= criterion(e_anc, e_pos, e_neg)/ accumulation_steps     # ì†ì‹¤ ë‚˜ëˆ—ì…ˆ

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            # ëˆ„ì  íšŸìˆ˜ê°€ ì°¨ë©´ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            if (i+ 1)%accumulation_steps == 0:
                optimizer.step()
                optimizer.zero_grad()

            optimizer.zero_grad()

            # íŠ¹ì§• ì¶”ì¶œ
            e_anc = dinov2(anc)
            e_pos = dinov2(pos)
            e_neg = dinov2(neg)

            loss = criterion(e_anc, e_pos, e_neg)
            loss.backward()
            optimizer.step()

            model_loss += loss.item()

        print(f"Epoch [{epoch + 1}/{num_epochs}] - Loss: {model_loss / len(loader):.4f}")

    # 5. ëª¨ë¸ ì €ì¥
    save_path = "dinov2_semicon_contrastive.pt"
    torch.save(dinov2.state_dict(), save_path)
    print(f"âœ… í•™ìŠµ ì™„ë£Œ! ê°€ì¤‘ì¹˜ ì €ì¥ë¨: {save_path}")


if __name__ == "__main__":
    train()